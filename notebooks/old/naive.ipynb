{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Models\n",
    "\n",
    "This notebook can be used to test the performance of some simple models that only use the features at time $t$ to predict the response at time $t$ and ignore any information contained in the past. The models we tried first applied some feature reduction using principal component analysis or partial least squares with respect to the response. On the new features we then trained classifiers to predict whether the response is positive or negative. The classifiers we tried are gradient-boosted decision trees and support vector machines with a Gaussian kernel.\n",
    "\n",
    "The random forest seems highly overfit and the linear model highly underfit...\n",
    "\n",
    "If one prevents temporal data-leakage by choosing test and training sets consisting of different days, the best results seem be an F1 score of about 57%, with the recall being much higher than the precision (in fact the precision is generally terrible around 52%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install datatable\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import datatable as dt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn.kernel_approximation import Nystroem\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of data files\n",
    "comp_folder = os.path.join(os.pardir, \"input\", \"jane-street-market-prediction\")\n",
    "\n",
    "# read the data with datatables, then convert to pandas (faster)\n",
    "df = dt.fread(os.path.join(comp_folder, \"train.csv\")).to_pandas()\n",
    "df.set_index(\"ts_id\", inplace=True)\n",
    "\n",
    "# reduce memory usage\n",
    "df = df.astype({c: np.float32 for c in df.select_dtypes(include=\"float64\").columns})\n",
    "\n",
    "# split into training and test sets\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# split by date, to reduce temporal correlations between training/test\n",
    "train_df = df[df[\"date\"] < 350]\n",
    "test_df = df[df[\"date\"] >= 400]\n",
    "\n",
    "# split into features and target\n",
    "feat_cols = [c for c in train_df.columns if \"feature\" in c]\n",
    "train_X = train_df[feat_cols]\n",
    "test_X = test_df[feat_cols]\n",
    "train_y = train_df[\"resp\"]\n",
    "test_y = test_df[\"resp\"]\n",
    "train_weights = train_df[\"weight\"]\n",
    "test_weights = test_df[\"weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score the targets\n",
    "train_y = train_y / train_y.std()\n",
    "\n",
    "# targets as classification problem\n",
    "train_y_pos = train_y.gt(0).astype(int)\n",
    "\n",
    "# replace missing values by median\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "flow = imp.fit_transform(train_X)\n",
    "\n",
    "# z-score the features\n",
    "ss = StandardScaler()\n",
    "flow = ss.fit_transform(flow)\n",
    "\n",
    "# rotate features onto directions that cause maximal\n",
    "# variance in the response\n",
    "pls = PLSRegression(n_components=60) # 40 PCA components carry 95% variance\n",
    "pls.fit(flow, train_y)\n",
    "flow = pls.transform(flow)\n",
    "\n",
    "# pca = PCA(n_components=50)\n",
    "# flow = pca.fit_transform(flow)\n",
    "\n",
    "# train an ensemble of gradient boosted\n",
    "# decision trees on the new features\n",
    "clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=11,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.7,\n",
    "    random_state=42,\n",
    "    tree_method=\"gpu_hist\"\n",
    ")\n",
    "clf.fit(flow, train_y_pos)\n",
    "pred = clf.predict(flow)\n",
    "\n",
    "# transform the features with and approximate\n",
    "# RBF kernel\n",
    "# ker = Nystroem(kernel=\"rbf\", n_components=300, random_state=42)\n",
    "# flow = ker.fit_transform(flow)\n",
    "\n",
    "# re-z-score the features\n",
    "# ss2 = StandardScaler()\n",
    "# flow = ss2.fit_transform(flow)\n",
    "\n",
    "# fit a linear classifier\n",
    "# svc = SGDClassifier(loss=\"log\", random_state=42)\n",
    "# svc.fit(flow, train_y_pos)\n",
    "# pred = svc.predict(flow)\n",
    "\n",
    "# metric on training data\n",
    "print(\"TRAINING SET:\")\n",
    "print(f\"Confusion matrix:\")\n",
    "print(confusion_matrix(train_y_pos, pred))\n",
    "print(f\"Precision: {precision_score(train_y_pos, pred)}\")\n",
    "print(f\"Recall: {recall_score(train_y_pos, pred)}\")\n",
    "print(f\"F1: {f1_score(train_y_pos, pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = imp.transform(test_X)\n",
    "flow = ss.transform(flow)\n",
    "flow = pls.transform(flow)\n",
    "# flow = pca.transform(flow)\n",
    "pred = clf.predict(flow)\n",
    "# flow = ker.transform(flow)\n",
    "# flow = ss2.transform(flow)\n",
    "# pred = svc.predict(flow)\n",
    "\n",
    "test_y_pos = test_y.gt(0).astype(int)\n",
    "\n",
    "print(\"TEST SET:\")\n",
    "print(f\"Confusion matrix:\")\n",
    "print(confusion_matrix(test_y_pos, pred))\n",
    "print(f\"Precision: {precision_score(test_y_pos, pred)}\")\n",
    "print(f\"Recall: {recall_score(test_y_pos, pred)}\")\n",
    "print(f\"F1: {f1_score(test_y_pos, pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
